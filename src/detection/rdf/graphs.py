from matplotlib import pyplot as plt


def graph_scores_vs_feature_numbers():
    features = range(50, 2001, 50)
    precision = [0.7511622812355475, 0.7703218767048554, 0.7752669181986032, 0.7761502311832033, 0.7747807271105531,
                 0.7848489453108812, 0.7784537664489319, 0.7900311691056051, 0.7954879222160328, 0.79327042645015,
                 0.7917880142745806, 0.7943425471454405, 0.7889415268002166, 0.7895592999769551, 0.7858906890443372,
                 0.7931161164458183, 0.794208215069887, 0.7916094426161541, 0.7866324862535296, 0.7884835187934364,
                 0.7791147141546467, 0.7960782764433207, 0.7977146182433773, 0.7939584180561203, 0.7905051639269347,
                 0.7899679221854304, 0.7847080940485694, 0.7947925227305339, 0.8022661171378555, 0.7992698929505204,
                 0.7933892638617296, 0.7996250726091778, 0.8030567571793402, 0.8060139785803503, 0.798359173126615,
                 0.7966186172794166, 0.8000415444135747, 0.7972260640379948, 0.7921846548855732, 0.7992588180795447]
    recall = [0.19640288685513538, 0.31452464900780264, 0.2458536461184018, 0.26067614525921873, 0.29852475083690794,
              0.36159515293458755, 0.36482186270890876, 0.3807008388172549, 0.3998956251670634, 0.34509883787533574,
              0.36855135369066866, 0.3913928948741774, 0.3709570663034762, 0.37068976490205313, 0.38682331377365936,
              0.39845092473556254, 0.37753777223374874, 0.3888471672415768, 0.4042551837378919, 0.3819673383144737,
              0.32967809274085763, 0.38472945279584536, 0.38387026971984267, 0.39761083461680435, 0.385321334470425,
              0.3886944235836208, 0.3878543334648626, 0.3877652329977216, 0.37041609918154855, 0.4124587910339473,
              0.40023929839746447, 0.38548680676654407, 0.39225207795018013, 0.38605323116479767, 0.3932703690032203,
              0.3865369194149918, 0.3921947990784466, 0.3888662601988213, 0.3848694678156384, 0.3843285006937108]
    f1score = [0.31138848387308343, 0.4466718787424135, 0.3733196749036018, 0.390275276562902, 0.43098862023182194,
               0.49509186683339357, 0.4968127472775098, 0.5138076463868203, 0.5322344291316906, 0.4809629192703599,
               0.5029813734729419, 0.5244003308519437, 0.504636243214462, 0.5045150393035794, 0.5184569125455825,
               0.5304239528263521, 0.5117894210113106, 0.5215186848080304, 0.5340558446908867, 0.5146306641571237,
               0.4633093782561837, 0.5187546661403403, 0.5183189608871817, 0.5298667593951165, 0.5181011060479644,
               0.5210247485475904, 0.5191236349387532, 0.5212310456188378, 0.5068249206480518, 0.5441249317828807,
               0.5320676337085591, 0.5201954705119507, 0.5270615801670985, 0.5220583172679703, 0.526960763412159,
               0.5205106120402627, 0.5263589463254638, 0.5227490503405086, 0.51805211104115, 0.5190625792393878]
    plt.plot(features, precision, "k--")
    plt.plot(features, recall, "b:")
    plt.plot(features, f1score, "r")
    plt.ylim([0, 1])
    plt.legend(("Precision", "Recall", "F1 score"))
    plt.xlabel("Number of features")
    plt.ylabel("Score")
    plt.title("Relation between the number of features and the score", pad=15)
    plt.savefig("./figures/RdfNumberOfFeatures.pdf")
    plt.show()


def graph_scores_vs_trees_per_iter():
    trees_per_iter = range(1, 13)
    precision = [0.8097722157900898, 0.8155555839738098, 0.8067158840916145, 0.8327497308629385, 0.8321569643204041,
                 0.8231159159716503, 0.8138271717876296, 0.8242488162825663, 0.839712298587412, 0.8368173361059429,
                 0.8244279923620649, 0.8352814696923385]
    recall = [0.4015404165833457, 0.41138411719551293, 0.38556859304748325, 0.47403288544280525, 0.4973842591099385,
              0.4577385291214852, 0.4590931668204073, 0.4738780697057856, 0.5015642840094695, 0.4932171355218258,
              0.47625191100675385, 0.511208014294653]
    f1score = [0.5368659818710273, 0.5468999228196553, 0.5217619022678468, 0.6041567324925596, 0.6226234551701584,
               0.5883133249320157, 0.5870320116796027, 0.6017800605368033, 0.6280131976948456, 0.6206345147792348,
               0.6037387151642025, 0.6342456982793118]
    plt.plot(trees_per_iter, precision, "k--")
    plt.plot(trees_per_iter, recall, "b:")
    plt.plot(trees_per_iter, f1score, "r")
    plt.ylim([0, 1])
    plt.legend(("Precision", "Recall", "F1 score"))
    plt.xlabel("Number of trees")
    plt.ylabel("Score")
    plt.title("Relation between the number of learned trees per iteration and the score", pad=15)
    plt.savefig("./figures/RdfNumberOfTreesPerIter.pdf")
    plt.show()


def graph_scores_vs_tree_height():
    trees_per_iter = range(4, 25, 2)
    precision = [0.0, 0.8827329752469669, 0.8414729583959052, 0.8315789473684211, 0.8281391830559758,
                 0.8294398230884943, 0.829680732729037, 0.8300304278993521, 0.8288679514946294, 0.8316241354638684,
                 0.8328462447620071]
    recall = [0.0, 0.1515968598208008, 0.2566328867329364, 0.32053953284351355, 0.3707643381949775, 0.41615115176457684,
              0.4522748237358327, 0.4768647232991234, 0.4863342858801597, 0.4948556020719506, 0.5000096759835637]
    f1score = [0.0, 0.25875604197174723, 0.39331296774129765, 0.46271964540129806, 0.5122088152993387,
               0.5542306337574419, 0.5854238943927458, 0.605729128258073, 0.6129960728833816, 0.6204902353307532,
               0.6248705122675771]
    plt.plot(trees_per_iter, precision, "k--")
    plt.plot(trees_per_iter, recall, "b:")
    plt.plot(trees_per_iter, f1score, "r")
    plt.ylim([0, 1])
    plt.legend(("Precision", "Recall", "F1 score"))
    plt.xlabel("Tree height")
    plt.ylabel("Score")
    plt.title("Relation between the tree height and the score", pad=15)
    plt.savefig("./figures/RdfTreeHeight.pdf")
    plt.show()


if __name__ == '__main__':
    # graph_scores_vs_feature_numbers()
    # graph_scores_vs_trees_per_iter()
    graph_scores_vs_tree_height()
